{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jeOW_Ig_uK4u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directory if it doesn't exist\n",
        "os.makedirs('output', exist_ok=True)"
      ],
      "metadata": {
        "id": "2QLZkD25ul5q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "metadata": {
        "id": "RGM1G--BwLsg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "metadata": {
        "id": "qPFc_lt9wPh0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create the generator and discriminator\n",
        "netG = Generator().to(device)\n",
        "netD = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "wM5Z4Qm_wQqX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the weights\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBfQveCDwUkJ",
        "outputId": "3393695d-8399-49bb-9a8f-5ec6360da487"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (6): Dropout(p=0.3, inplace=False)\n",
              "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (10): Dropout(p=0.3, inplace=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (15): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "schedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=10, gamma=0.1)\n",
        "schedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "latent_vector_size = 100"
      ],
      "metadata": {
        "id": "kPRnF_Z0wXfQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformation for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "hF1rfhXywbF7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig-QkNQLwdyr",
        "outputId": "c5f9c8d6-1763-4674-da43-200ff25c4421"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:15<00:00, 11155265.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert RGB images to grayscale\n",
        "def rgb_to_grayscale(batch):\n",
        "    return batch.mean(dim=1, keepdim=True)\n"
      ],
      "metadata": {
        "id": "0KOy2WC-wgpb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # Update Discriminator\n",
        "        netD.zero_grad()\n",
        "        real_images, _ = data\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        grayscale_images = rgb_to_grayscale(real_images)\n",
        "\n",
        "        batch_size = real_images.size(0)\n",
        "        real_labels = torch.full((batch_size,), 0.9, dtype=torch.float, device=device)\n",
        "        fake_labels = torch.full((batch_size,), 0.1, dtype=torch.float, device=device)\n",
        "\n",
        "        output = netD(real_images).view(-1)\n",
        "        errD_real = criterion(output, real_labels)\n",
        "        errD_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, latent_vector_size, 1, 1, device=device)\n",
        "        fake_images = netG(noise)\n",
        "        output = netD(fake_images.detach()).view(-1)\n",
        "        errD_fake = criterion(output, fake_labels)\n",
        "        errD_fake.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        # Update Generator\n",
        "        netG.zero_grad()\n",
        "        real_labels.fill_(1)\n",
        "        output = netD(fake_images).view(-1)\n",
        "        errG = criterion(output, real_labels)\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD_real.item() + errD_fake.item()} Loss_G: {errG.item()}')\n",
        "\n",
        "    # Save generated images every epoch\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(64, latent_vector_size, 1, 1, device=device)\n",
        "        fake_images = netG(noise).detach().cpu()\n",
        "        save_image(fake_images, f'output/fake_images_epoch_{epoch}.png', normalize=True)\n",
        "\n",
        "    # Adjust learning rate\n",
        "    schedulerD.step()\n",
        "    schedulerG.step()\n",
        "\n",
        "print('Training finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfmhVdmwq7_",
        "outputId": "82e07143-ba46-4226-ac27-9d21f6a5fc69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/50][0/782] Loss_D: 1.638987421989441 Loss_G: 1.3647303581237793\n",
            "[0/50][100/782] Loss_D: 0.8063732087612152 Loss_G: 2.396559000015259\n",
            "[0/50][200/782] Loss_D: 0.8122829794883728 Loss_G: 3.898791790008545\n",
            "[0/50][300/782] Loss_D: 0.8122454881668091 Loss_G: 2.5928597450256348\n",
            "[0/50][400/782] Loss_D: 0.8059958219528198 Loss_G: 3.5814950466156006\n",
            "[0/50][500/782] Loss_D: 0.9128357768058777 Loss_G: 3.64278507232666\n",
            "[0/50][600/782] Loss_D: 0.8553335070610046 Loss_G: 5.585565567016602\n",
            "[0/50][700/782] Loss_D: 0.8134957551956177 Loss_G: 3.0699892044067383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv_transpose2d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/50][0/782] Loss_D: 0.7672998011112213 Loss_G: 2.7860302925109863\n",
            "[1/50][100/782] Loss_D: 0.9705862402915955 Loss_G: 2.52182674407959\n",
            "[1/50][200/782] Loss_D: 0.7904083728790283 Loss_G: 3.916564464569092\n",
            "[1/50][300/782] Loss_D: 0.866606742143631 Loss_G: 2.238795518875122\n",
            "[1/50][400/782] Loss_D: 0.76784548163414 Loss_G: 2.450723171234131\n",
            "[1/50][500/782] Loss_D: 0.7976526021957397 Loss_G: 2.8430893421173096\n",
            "[1/50][600/782] Loss_D: 0.9038259387016296 Loss_G: 3.626544237136841\n",
            "[1/50][700/782] Loss_D: 0.7813024520874023 Loss_G: 2.3806233406066895\n",
            "[2/50][0/782] Loss_D: 0.9762203097343445 Loss_G: 3.2030699253082275\n",
            "[2/50][100/782] Loss_D: 0.9232001006603241 Loss_G: 1.9121179580688477\n",
            "[2/50][200/782] Loss_D: 0.9463008344173431 Loss_G: 4.486671447753906\n",
            "[2/50][300/782] Loss_D: 0.7438027858734131 Loss_G: 3.7400026321411133\n",
            "[2/50][400/782] Loss_D: 0.9862045645713806 Loss_G: 1.543668508529663\n",
            "[2/50][500/782] Loss_D: 0.9402974247932434 Loss_G: 3.53641939163208\n",
            "[2/50][600/782] Loss_D: 0.8235722482204437 Loss_G: 1.9794902801513672\n",
            "[2/50][700/782] Loss_D: 1.3312551379203796 Loss_G: 3.504331588745117\n",
            "[3/50][0/782] Loss_D: 0.8996926546096802 Loss_G: 2.028665065765381\n",
            "[3/50][100/782] Loss_D: 1.0008808970451355 Loss_G: 3.1937618255615234\n",
            "[3/50][200/782] Loss_D: 1.1590355038642883 Loss_G: 1.174706220626831\n",
            "[3/50][300/782] Loss_D: 0.8367815017700195 Loss_G: 2.4623351097106934\n",
            "[3/50][400/782] Loss_D: 0.985740453004837 Loss_G: 3.132279396057129\n",
            "[3/50][500/782] Loss_D: 1.2572934925556183 Loss_G: 1.060705542564392\n",
            "[3/50][600/782] Loss_D: 0.8633542656898499 Loss_G: 1.5727109909057617\n",
            "[3/50][700/782] Loss_D: 1.0159224271774292 Loss_G: 2.9237184524536133\n",
            "[4/50][0/782] Loss_D: 0.9836921095848083 Loss_G: 1.3663742542266846\n",
            "[4/50][100/782] Loss_D: 1.0075576901435852 Loss_G: 3.6142759323120117\n",
            "[4/50][200/782] Loss_D: 0.9080636203289032 Loss_G: 2.1550862789154053\n",
            "[4/50][300/782] Loss_D: 0.8584023416042328 Loss_G: 1.773061990737915\n",
            "[4/50][400/782] Loss_D: 0.7786213755607605 Loss_G: 2.3458364009857178\n",
            "[4/50][500/782] Loss_D: 1.181379497051239 Loss_G: 2.95198130607605\n",
            "[4/50][600/782] Loss_D: 0.8220731616020203 Loss_G: 1.9885965585708618\n",
            "[4/50][700/782] Loss_D: 0.8729875683784485 Loss_G: 1.730727195739746\n",
            "[5/50][0/782] Loss_D: 0.9368636310100555 Loss_G: 2.5921168327331543\n",
            "[5/50][100/782] Loss_D: 1.0301743149757385 Loss_G: 2.864506721496582\n",
            "[5/50][200/782] Loss_D: 1.2605071067810059 Loss_G: 1.531117558479309\n",
            "[5/50][300/782] Loss_D: 0.9575084447860718 Loss_G: 1.7988073825836182\n",
            "[5/50][400/782] Loss_D: 0.8216583430767059 Loss_G: 1.9532501697540283\n",
            "[5/50][500/782] Loss_D: 0.8927032053470612 Loss_G: 2.107156276702881\n",
            "[5/50][600/782] Loss_D: 0.8851924538612366 Loss_G: 1.645485281944275\n",
            "[5/50][700/782] Loss_D: 0.8127028346061707 Loss_G: 1.8955610990524292\n",
            "[6/50][0/782] Loss_D: 1.0571239590644836 Loss_G: 2.544686794281006\n",
            "[6/50][100/782] Loss_D: 0.9040953516960144 Loss_G: 1.7870588302612305\n",
            "[6/50][200/782] Loss_D: 0.8230066895484924 Loss_G: 1.634232521057129\n",
            "[6/50][300/782] Loss_D: 1.1367341876029968 Loss_G: 2.902245044708252\n",
            "[6/50][400/782] Loss_D: 1.0376798808574677 Loss_G: 0.9095964431762695\n",
            "[6/50][500/782] Loss_D: 0.8264100551605225 Loss_G: 1.7157816886901855\n",
            "[6/50][600/782] Loss_D: 1.3437795639038086 Loss_G: 1.3441890478134155\n",
            "[6/50][700/782] Loss_D: 0.8133412599563599 Loss_G: 2.23293137550354\n",
            "[7/50][0/782] Loss_D: 1.5206868648529053 Loss_G: 3.642185688018799\n",
            "[7/50][100/782] Loss_D: 0.8073621392250061 Loss_G: 2.4668774604797363\n",
            "[7/50][200/782] Loss_D: 1.0123646557331085 Loss_G: 1.7780157327651978\n",
            "[7/50][300/782] Loss_D: 0.7981254160404205 Loss_G: 1.6338225603103638\n",
            "[7/50][400/782] Loss_D: 0.9597303867340088 Loss_G: 2.2363128662109375\n",
            "[7/50][500/782] Loss_D: 0.9512143135070801 Loss_G: 1.5362470149993896\n",
            "[7/50][600/782] Loss_D: 0.7569701373577118 Loss_G: 2.049304246902466\n",
            "[7/50][700/782] Loss_D: 0.7703317701816559 Loss_G: 2.174473762512207\n",
            "[8/50][0/782] Loss_D: 1.6532133221626282 Loss_G: 0.33400213718414307\n",
            "[8/50][100/782] Loss_D: 0.9628666639328003 Loss_G: 1.9812673330307007\n",
            "[8/50][200/782] Loss_D: 1.1167577505111694 Loss_G: 3.2733688354492188\n",
            "[8/50][300/782] Loss_D: 0.7679904103279114 Loss_G: 2.271275043487549\n",
            "[8/50][400/782] Loss_D: 1.2308179140090942 Loss_G: 2.075608730316162\n",
            "[8/50][500/782] Loss_D: 0.7849472165107727 Loss_G: 2.0323171615600586\n",
            "[8/50][600/782] Loss_D: 0.9587010145187378 Loss_G: 1.7398011684417725\n",
            "[8/50][700/782] Loss_D: 1.1536409556865692 Loss_G: 1.259171724319458\n",
            "[9/50][0/782] Loss_D: 0.9108982682228088 Loss_G: 2.271160125732422\n",
            "[9/50][100/782] Loss_D: 1.096450686454773 Loss_G: 2.807934284210205\n",
            "[9/50][200/782] Loss_D: 0.8027042150497437 Loss_G: 2.0340352058410645\n",
            "[9/50][300/782] Loss_D: 0.9069285094738007 Loss_G: 1.939132571220398\n",
            "[9/50][400/782] Loss_D: 0.8694745898246765 Loss_G: 1.3349473476409912\n",
            "[9/50][500/782] Loss_D: 1.348181962966919 Loss_G: 0.8162866830825806\n",
            "[9/50][600/782] Loss_D: 0.9620278179645538 Loss_G: 1.5927172899246216\n",
            "[9/50][700/782] Loss_D: 1.0253559350967407 Loss_G: 2.2642953395843506\n",
            "[10/50][0/782] Loss_D: 1.5576042532920837 Loss_G: 0.4007740616798401\n",
            "[10/50][100/782] Loss_D: 0.9166926443576813 Loss_G: 1.2292901277542114\n",
            "[10/50][200/782] Loss_D: 0.7760342061519623 Loss_G: 1.545143961906433\n",
            "[10/50][300/782] Loss_D: 0.9837688207626343 Loss_G: 1.422149658203125\n",
            "[10/50][400/782] Loss_D: 0.8154878318309784 Loss_G: 1.5496152639389038\n",
            "[10/50][500/782] Loss_D: 0.8380644023418427 Loss_G: 1.4470643997192383\n",
            "[10/50][600/782] Loss_D: 0.8991419076919556 Loss_G: 1.6808911561965942\n",
            "[10/50][700/782] Loss_D: 0.8678039908409119 Loss_G: 1.7252137660980225\n",
            "[11/50][0/782] Loss_D: 0.7909770309925079 Loss_G: 1.384475827217102\n",
            "[11/50][100/782] Loss_D: 0.8933905959129333 Loss_G: 1.805509090423584\n",
            "[11/50][200/782] Loss_D: 0.9199278056621552 Loss_G: 1.7161400318145752\n",
            "[11/50][300/782] Loss_D: 0.8078403770923615 Loss_G: 1.755744218826294\n",
            "[11/50][400/782] Loss_D: 0.7208757996559143 Loss_G: 1.868698000907898\n",
            "[11/50][500/782] Loss_D: 0.8237993121147156 Loss_G: 1.7640581130981445\n",
            "[11/50][600/782] Loss_D: 0.7113848924636841 Loss_G: 1.6323992013931274\n",
            "[11/50][700/782] Loss_D: 0.7945942580699921 Loss_G: 1.8604429960250854\n",
            "[12/50][0/782] Loss_D: 0.7386123538017273 Loss_G: 1.9524471759796143\n",
            "[12/50][100/782] Loss_D: 0.7042482197284698 Loss_G: 1.7761244773864746\n",
            "[12/50][200/782] Loss_D: 0.7706036269664764 Loss_G: 2.0938262939453125\n",
            "[12/50][300/782] Loss_D: 0.8488242030143738 Loss_G: 1.580742597579956\n",
            "[12/50][400/782] Loss_D: 0.7651077508926392 Loss_G: 1.7084577083587646\n",
            "[12/50][500/782] Loss_D: 0.7496199607849121 Loss_G: 1.4973368644714355\n",
            "[12/50][600/782] Loss_D: 0.8309887051582336 Loss_G: 1.3548552989959717\n",
            "[12/50][700/782] Loss_D: 0.7696419060230255 Loss_G: 1.626423954963684\n",
            "[13/50][0/782] Loss_D: 0.7931471467018127 Loss_G: 1.1329398155212402\n",
            "[13/50][100/782] Loss_D: 0.8043557405471802 Loss_G: 1.5987062454223633\n",
            "[13/50][200/782] Loss_D: 0.8189752101898193 Loss_G: 1.6703062057495117\n",
            "[13/50][300/782] Loss_D: 0.7486487925052643 Loss_G: 2.012861490249634\n",
            "[13/50][400/782] Loss_D: 0.9037238955497742 Loss_G: 1.9309961795806885\n",
            "[13/50][500/782] Loss_D: 0.7216712534427643 Loss_G: 1.7890031337738037\n",
            "[13/50][600/782] Loss_D: 0.7380490005016327 Loss_G: 2.0738556385040283\n",
            "[13/50][700/782] Loss_D: 0.8455877304077148 Loss_G: 1.675586223602295\n",
            "[14/50][0/782] Loss_D: 0.7592368423938751 Loss_G: 1.478569507598877\n",
            "[14/50][100/782] Loss_D: 0.7537814974784851 Loss_G: 1.6697790622711182\n",
            "[14/50][200/782] Loss_D: 0.7588924169540405 Loss_G: 1.9386334419250488\n",
            "[14/50][300/782] Loss_D: 0.7624564170837402 Loss_G: 2.2612340450286865\n",
            "[14/50][400/782] Loss_D: 0.7038408517837524 Loss_G: 1.9917227029800415\n",
            "[14/50][500/782] Loss_D: 0.8102065324783325 Loss_G: 1.54701566696167\n",
            "[14/50][600/782] Loss_D: 0.8625248670578003 Loss_G: 1.536512851715088\n",
            "[14/50][700/782] Loss_D: 0.7519190907478333 Loss_G: 2.128099203109741\n",
            "[15/50][0/782] Loss_D: 0.7333226203918457 Loss_G: 1.7663511037826538\n",
            "[15/50][100/782] Loss_D: 0.7231972515583038 Loss_G: 2.021237850189209\n",
            "[15/50][200/782] Loss_D: 0.729614794254303 Loss_G: 2.215606212615967\n",
            "[15/50][300/782] Loss_D: 0.7400431334972382 Loss_G: 2.1032228469848633\n",
            "[15/50][400/782] Loss_D: 0.821919858455658 Loss_G: 1.2815860509872437\n",
            "[15/50][500/782] Loss_D: 0.7419001758098602 Loss_G: 1.7884528636932373\n",
            "[15/50][600/782] Loss_D: 0.7432216107845306 Loss_G: 1.7163729667663574\n",
            "[15/50][700/782] Loss_D: 0.7420253753662109 Loss_G: 2.1878390312194824\n",
            "[16/50][0/782] Loss_D: 0.7313448190689087 Loss_G: 2.4258713722229004\n",
            "[16/50][100/782] Loss_D: 0.8170484602451324 Loss_G: 1.9390240907669067\n",
            "[16/50][200/782] Loss_D: 0.7480885088443756 Loss_G: 1.7076070308685303\n",
            "[16/50][300/782] Loss_D: 0.7395228147506714 Loss_G: 1.9432082176208496\n",
            "[16/50][400/782] Loss_D: 0.7465523183345795 Loss_G: 1.9375301599502563\n",
            "[16/50][500/782] Loss_D: 0.7708986103534698 Loss_G: 1.5208206176757812\n",
            "[16/50][600/782] Loss_D: 0.6964203119277954 Loss_G: 1.9778395891189575\n",
            "[16/50][700/782] Loss_D: 0.7294580340385437 Loss_G: 1.9978538751602173\n",
            "[17/50][0/782] Loss_D: 0.7222467958927155 Loss_G: 1.9793579578399658\n",
            "[17/50][100/782] Loss_D: 0.7124083340167999 Loss_G: 1.792606234550476\n",
            "[17/50][200/782] Loss_D: 0.8102867007255554 Loss_G: 1.91829252243042\n",
            "[17/50][300/782] Loss_D: 0.7287056744098663 Loss_G: 1.7250396013259888\n",
            "[17/50][400/782] Loss_D: 0.7086309194564819 Loss_G: 2.044978380203247\n",
            "[17/50][500/782] Loss_D: 0.7521442472934723 Loss_G: 1.5178070068359375\n",
            "[17/50][600/782] Loss_D: 0.7122185826301575 Loss_G: 2.423236131668091\n",
            "[17/50][700/782] Loss_D: 0.7242353558540344 Loss_G: 1.8355889320373535\n",
            "[18/50][0/782] Loss_D: 0.6953965425491333 Loss_G: 1.6537539958953857\n",
            "[18/50][100/782] Loss_D: 0.7944134175777435 Loss_G: 2.1063833236694336\n",
            "[18/50][200/782] Loss_D: 0.7279854118824005 Loss_G: 1.933836817741394\n",
            "[18/50][300/782] Loss_D: 0.869450032711029 Loss_G: 1.7949246168136597\n",
            "[18/50][400/782] Loss_D: 0.7177130281925201 Loss_G: 2.2344465255737305\n",
            "[18/50][500/782] Loss_D: 0.8194780349731445 Loss_G: 1.8665354251861572\n",
            "[18/50][600/782] Loss_D: 0.7039113938808441 Loss_G: 1.871604323387146\n",
            "[18/50][700/782] Loss_D: 0.8617489337921143 Loss_G: 2.024831771850586\n",
            "[19/50][0/782] Loss_D: 0.7213835716247559 Loss_G: 2.387664794921875\n",
            "[19/50][100/782] Loss_D: 0.6828474700450897 Loss_G: 2.219409942626953\n",
            "[19/50][200/782] Loss_D: 0.7341806888580322 Loss_G: 2.0247323513031006\n",
            "[19/50][300/782] Loss_D: 0.711952269077301 Loss_G: 2.661416530609131\n",
            "[19/50][400/782] Loss_D: 0.7668088376522064 Loss_G: 2.315763473510742\n",
            "[19/50][500/782] Loss_D: 0.7637203335762024 Loss_G: 1.8258533477783203\n",
            "[19/50][600/782] Loss_D: 0.7323558628559113 Loss_G: 1.773268461227417\n",
            "[19/50][700/782] Loss_D: 0.7237885892391205 Loss_G: 1.9102916717529297\n",
            "[20/50][0/782] Loss_D: 0.6862927675247192 Loss_G: 2.028066396713257\n",
            "[20/50][100/782] Loss_D: 0.7756056785583496 Loss_G: 2.763631820678711\n",
            "[20/50][200/782] Loss_D: 0.6998002231121063 Loss_G: 2.2449729442596436\n",
            "[20/50][300/782] Loss_D: 0.7092437744140625 Loss_G: 2.335299491882324\n",
            "[20/50][400/782] Loss_D: 0.7186518013477325 Loss_G: 1.9311022758483887\n",
            "[20/50][500/782] Loss_D: 0.6786613464355469 Loss_G: 2.0268452167510986\n",
            "[20/50][600/782] Loss_D: 0.6802399754524231 Loss_G: 2.4580254554748535\n",
            "[20/50][700/782] Loss_D: 0.6969626545906067 Loss_G: 1.9421697854995728\n",
            "[21/50][0/782] Loss_D: 0.6845989227294922 Loss_G: 1.9990081787109375\n",
            "[21/50][100/782] Loss_D: 0.7126665115356445 Loss_G: 2.146707534790039\n",
            "[21/50][200/782] Loss_D: 0.7684018313884735 Loss_G: 1.872367024421692\n",
            "[21/50][300/782] Loss_D: 0.6850203573703766 Loss_G: 1.7528538703918457\n",
            "[21/50][400/782] Loss_D: 0.7312401533126831 Loss_G: 2.2019619941711426\n",
            "[21/50][500/782] Loss_D: 0.7442648410797119 Loss_G: 1.9352970123291016\n",
            "[21/50][600/782] Loss_D: 0.6826432645320892 Loss_G: 2.4521594047546387\n",
            "[21/50][700/782] Loss_D: 0.7589442133903503 Loss_G: 2.1286821365356445\n",
            "[22/50][0/782] Loss_D: 0.7177026271820068 Loss_G: 1.8007358312606812\n",
            "[22/50][100/782] Loss_D: 0.7510642111301422 Loss_G: 1.8161417245864868\n",
            "[22/50][200/782] Loss_D: 0.7055786550045013 Loss_G: 1.7566306591033936\n",
            "[22/50][300/782] Loss_D: 0.7577605843544006 Loss_G: 2.142012596130371\n",
            "[22/50][400/782] Loss_D: 0.7217825651168823 Loss_G: 1.8279614448547363\n",
            "[22/50][500/782] Loss_D: 0.7728069424629211 Loss_G: 2.394465446472168\n",
            "[22/50][600/782] Loss_D: 0.7165403068065643 Loss_G: 1.2930282354354858\n",
            "[22/50][700/782] Loss_D: 0.7404718697071075 Loss_G: 2.057098865509033\n",
            "[23/50][0/782] Loss_D: 0.688355565071106 Loss_G: 2.081310272216797\n",
            "[23/50][100/782] Loss_D: 0.7248992621898651 Loss_G: 1.911376714706421\n",
            "[23/50][200/782] Loss_D: 0.7201785147190094 Loss_G: 2.015984296798706\n",
            "[23/50][300/782] Loss_D: 0.773380845785141 Loss_G: 1.6469827890396118\n",
            "[23/50][400/782] Loss_D: 0.7160553932189941 Loss_G: 1.8227328062057495\n",
            "[23/50][500/782] Loss_D: 0.7168306708335876 Loss_G: 1.9886422157287598\n",
            "[23/50][600/782] Loss_D: 0.7271958887577057 Loss_G: 2.0771474838256836\n",
            "[23/50][700/782] Loss_D: 0.7157250046730042 Loss_G: 1.853463888168335\n",
            "[24/50][0/782] Loss_D: 0.6984388530254364 Loss_G: 2.4019761085510254\n",
            "[24/50][100/782] Loss_D: 0.7307105660438538 Loss_G: 2.054993152618408\n",
            "[24/50][200/782] Loss_D: 0.7382320165634155 Loss_G: 1.5701795816421509\n",
            "[24/50][300/782] Loss_D: 0.7041822373867035 Loss_G: 1.5193736553192139\n",
            "[24/50][400/782] Loss_D: 0.6826580762863159 Loss_G: 2.295850992202759\n",
            "[24/50][500/782] Loss_D: 0.6931068897247314 Loss_G: 1.9212809801101685\n",
            "[24/50][600/782] Loss_D: 0.7152683734893799 Loss_G: 1.6383473873138428\n",
            "[24/50][700/782] Loss_D: 0.7427151799201965 Loss_G: 1.8460159301757812\n",
            "[25/50][0/782] Loss_D: 0.6801516115665436 Loss_G: 2.0191640853881836\n",
            "[25/50][100/782] Loss_D: 0.6808335781097412 Loss_G: 2.249467134475708\n",
            "[25/50][200/782] Loss_D: 0.6985770761966705 Loss_G: 1.6844592094421387\n",
            "[25/50][300/782] Loss_D: 0.693653404712677 Loss_G: 2.202108860015869\n",
            "[25/50][400/782] Loss_D: 0.7115377485752106 Loss_G: 1.6380956172943115\n",
            "[25/50][500/782] Loss_D: 0.7410390973091125 Loss_G: 1.9380308389663696\n",
            "[25/50][600/782] Loss_D: 0.7602079510688782 Loss_G: 2.3496456146240234\n",
            "[25/50][700/782] Loss_D: 0.7215873301029205 Loss_G: 2.1217002868652344\n",
            "[26/50][0/782] Loss_D: 0.6734517216682434 Loss_G: 2.0219192504882812\n",
            "[26/50][100/782] Loss_D: 0.8025460243225098 Loss_G: 1.8331246376037598\n",
            "[26/50][200/782] Loss_D: 0.7503165602684021 Loss_G: 1.7773786783218384\n",
            "[26/50][300/782] Loss_D: 0.713144063949585 Loss_G: 2.3582839965820312\n",
            "[26/50][400/782] Loss_D: 0.6751351654529572 Loss_G: 1.887962818145752\n",
            "[26/50][500/782] Loss_D: 0.7141185402870178 Loss_G: 1.880285382270813\n",
            "[26/50][600/782] Loss_D: 0.6974553167819977 Loss_G: 2.024209976196289\n",
            "[26/50][700/782] Loss_D: 0.7691629528999329 Loss_G: 1.404231071472168\n",
            "[27/50][0/782] Loss_D: 0.7157176434993744 Loss_G: 1.6867226362228394\n",
            "[27/50][100/782] Loss_D: 0.6796764433383942 Loss_G: 2.385329484939575\n",
            "[27/50][200/782] Loss_D: 0.6769587993621826 Loss_G: 2.1712863445281982\n",
            "[27/50][300/782] Loss_D: 0.681249737739563 Loss_G: 2.0884978771209717\n",
            "[27/50][400/782] Loss_D: 0.6775841414928436 Loss_G: 2.216151475906372\n",
            "[27/50][500/782] Loss_D: 0.8383168578147888 Loss_G: 2.096421480178833\n",
            "[27/50][600/782] Loss_D: 0.6702003479003906 Loss_G: 2.4528093338012695\n",
            "[27/50][700/782] Loss_D: 0.7181525230407715 Loss_G: 1.797887921333313\n",
            "[28/50][0/782] Loss_D: 0.7175087332725525 Loss_G: 2.125704526901245\n",
            "[28/50][100/782] Loss_D: 0.6949746906757355 Loss_G: 1.8745090961456299\n",
            "[28/50][200/782] Loss_D: 0.6822367906570435 Loss_G: 2.214054822921753\n",
            "[28/50][300/782] Loss_D: 0.7040702402591705 Loss_G: 2.08101224899292\n",
            "[28/50][400/782] Loss_D: 0.716113805770874 Loss_G: 2.300220251083374\n",
            "[28/50][500/782] Loss_D: 0.7183535099029541 Loss_G: 2.1497929096221924\n",
            "[28/50][600/782] Loss_D: 0.7511680126190186 Loss_G: 2.2811598777770996\n",
            "[28/50][700/782] Loss_D: 0.7052799463272095 Loss_G: 1.8680059909820557\n",
            "[29/50][0/782] Loss_D: 0.7130932509899139 Loss_G: 1.5244468450546265\n",
            "[29/50][100/782] Loss_D: 0.6932646036148071 Loss_G: 1.9533426761627197\n",
            "[29/50][200/782] Loss_D: 0.7184658050537109 Loss_G: 1.9312970638275146\n",
            "[29/50][300/782] Loss_D: 0.6764171421527863 Loss_G: 2.2212021350860596\n",
            "[29/50][400/782] Loss_D: 0.6965379118919373 Loss_G: 2.275543212890625\n",
            "[29/50][500/782] Loss_D: 0.6850560307502747 Loss_G: 1.9939910173416138\n",
            "[29/50][600/782] Loss_D: 0.7187177538871765 Loss_G: 2.041520118713379\n",
            "[29/50][700/782] Loss_D: 0.6817338764667511 Loss_G: 1.9130319356918335\n",
            "[30/50][0/782] Loss_D: 0.6776638031005859 Loss_G: 1.6269354820251465\n",
            "[30/50][100/782] Loss_D: 0.7115010023117065 Loss_G: 1.7863723039627075\n",
            "[30/50][200/782] Loss_D: 0.6862966418266296 Loss_G: 1.7149590253829956\n",
            "[30/50][300/782] Loss_D: 0.6990718245506287 Loss_G: 2.134859561920166\n",
            "[30/50][400/782] Loss_D: 0.7145450711250305 Loss_G: 1.8661613464355469\n",
            "[30/50][500/782] Loss_D: 0.7020008563995361 Loss_G: 2.0738589763641357\n",
            "[30/50][600/782] Loss_D: 0.692713588476181 Loss_G: 2.088940143585205\n",
            "[30/50][700/782] Loss_D: 0.6804772615432739 Loss_G: 2.543191909790039\n",
            "[31/50][0/782] Loss_D: 0.6904678344726562 Loss_G: 1.7441298961639404\n",
            "[31/50][100/782] Loss_D: 0.7083051204681396 Loss_G: 1.8769173622131348\n",
            "[31/50][200/782] Loss_D: 0.6910508871078491 Loss_G: 2.1190505027770996\n",
            "[31/50][300/782] Loss_D: 0.6919328570365906 Loss_G: 1.9298760890960693\n",
            "[31/50][400/782] Loss_D: 0.7027274668216705 Loss_G: 2.185089588165283\n",
            "[31/50][500/782] Loss_D: 0.7160504460334778 Loss_G: 1.8702603578567505\n",
            "[31/50][600/782] Loss_D: 0.6790702939033508 Loss_G: 1.8172646760940552\n",
            "[31/50][700/782] Loss_D: 0.6940500736236572 Loss_G: 1.8921740055084229\n",
            "[32/50][0/782] Loss_D: 0.677560418844223 Loss_G: 2.1879520416259766\n",
            "[32/50][100/782] Loss_D: 0.6992805600166321 Loss_G: 1.7937266826629639\n",
            "[32/50][200/782] Loss_D: 0.7101818025112152 Loss_G: 1.8859955072402954\n",
            "[32/50][300/782] Loss_D: 0.6953701078891754 Loss_G: 1.891443133354187\n",
            "[32/50][400/782] Loss_D: 0.7059839367866516 Loss_G: 1.7427501678466797\n",
            "[32/50][500/782] Loss_D: 0.6755366921424866 Loss_G: 2.1892895698547363\n",
            "[32/50][600/782] Loss_D: 0.7539340257644653 Loss_G: 2.0211939811706543\n",
            "[32/50][700/782] Loss_D: 0.6959115266799927 Loss_G: 1.961247205734253\n",
            "[33/50][0/782] Loss_D: 0.7338854074478149 Loss_G: 2.293349266052246\n",
            "[33/50][100/782] Loss_D: 0.6907165944576263 Loss_G: 1.5019657611846924\n",
            "[33/50][200/782] Loss_D: 0.7053238749504089 Loss_G: 1.4992647171020508\n",
            "[33/50][300/782] Loss_D: 0.7037282288074493 Loss_G: 2.404625654220581\n",
            "[33/50][400/782] Loss_D: 0.7081528902053833 Loss_G: 1.8045392036437988\n",
            "[33/50][500/782] Loss_D: 0.7011603116989136 Loss_G: 1.945330023765564\n",
            "[33/50][600/782] Loss_D: 0.7177966833114624 Loss_G: 1.8762297630310059\n",
            "[33/50][700/782] Loss_D: 0.7404595911502838 Loss_G: 2.1453652381896973\n",
            "[34/50][0/782] Loss_D: 0.6955907046794891 Loss_G: 1.6737852096557617\n",
            "[34/50][100/782] Loss_D: 0.7186436653137207 Loss_G: 2.0711610317230225\n",
            "[34/50][200/782] Loss_D: 0.7244518101215363 Loss_G: 2.044067859649658\n",
            "[34/50][300/782] Loss_D: 0.6917905807495117 Loss_G: 1.9154876470565796\n",
            "[34/50][400/782] Loss_D: 0.6920989155769348 Loss_G: 2.0365686416625977\n",
            "[34/50][500/782] Loss_D: 0.6789945662021637 Loss_G: 2.1994409561157227\n",
            "[34/50][600/782] Loss_D: 0.6822218000888824 Loss_G: 1.8077561855316162\n",
            "[34/50][700/782] Loss_D: 0.767039567232132 Loss_G: 1.9551137685775757\n",
            "[35/50][0/782] Loss_D: 0.7242469191551208 Loss_G: 1.9935626983642578\n",
            "[35/50][100/782] Loss_D: 0.7207140326499939 Loss_G: 1.9446547031402588\n",
            "[35/50][200/782] Loss_D: 0.7103286385536194 Loss_G: 1.8743001222610474\n",
            "[35/50][300/782] Loss_D: 0.7320286929607391 Loss_G: 2.064645290374756\n",
            "[35/50][400/782] Loss_D: 0.7080737054347992 Loss_G: 1.705188274383545\n",
            "[35/50][500/782] Loss_D: 0.7102586030960083 Loss_G: 2.2631144523620605\n",
            "[35/50][600/782] Loss_D: 0.7224244773387909 Loss_G: 2.12615704536438\n",
            "[35/50][700/782] Loss_D: 0.8937948346138 Loss_G: 1.9115872383117676\n",
            "[36/50][0/782] Loss_D: 0.7873511016368866 Loss_G: 1.55290687084198\n",
            "[36/50][100/782] Loss_D: 0.72968789935112 Loss_G: 2.1219632625579834\n",
            "[36/50][200/782] Loss_D: 0.7049170434474945 Loss_G: 2.4804434776306152\n",
            "[36/50][300/782] Loss_D: 0.7182258367538452 Loss_G: 1.8718900680541992\n",
            "[36/50][400/782] Loss_D: 0.6819436252117157 Loss_G: 2.1439316272735596\n",
            "[36/50][500/782] Loss_D: 0.7311938107013702 Loss_G: 2.370300769805908\n",
            "[36/50][600/782] Loss_D: 0.695680171251297 Loss_G: 1.9601528644561768\n",
            "[36/50][700/782] Loss_D: 0.696387529373169 Loss_G: 2.0389859676361084\n",
            "[37/50][0/782] Loss_D: 0.7480241656303406 Loss_G: 2.245576858520508\n",
            "[37/50][100/782] Loss_D: 0.718573272228241 Loss_G: 1.8468575477600098\n",
            "[37/50][200/782] Loss_D: 0.735345721244812 Loss_G: 2.067128896713257\n",
            "[37/50][300/782] Loss_D: 0.7053532004356384 Loss_G: 2.0264551639556885\n",
            "[37/50][400/782] Loss_D: 0.7804726660251617 Loss_G: 1.6919134855270386\n",
            "[37/50][500/782] Loss_D: 0.6975775361061096 Loss_G: 2.1223883628845215\n",
            "[37/50][600/782] Loss_D: 0.7731970548629761 Loss_G: 1.87383234500885\n",
            "[37/50][700/782] Loss_D: 0.7095037996768951 Loss_G: 1.781740665435791\n",
            "[38/50][0/782] Loss_D: 0.7626087069511414 Loss_G: 2.042750597000122\n",
            "[38/50][100/782] Loss_D: 0.7013717591762543 Loss_G: 1.9716519117355347\n",
            "[38/50][200/782] Loss_D: 0.759541243314743 Loss_G: 1.6958378553390503\n",
            "[38/50][300/782] Loss_D: 0.7151951789855957 Loss_G: 1.876671314239502\n",
            "[38/50][400/782] Loss_D: 0.7255807220935822 Loss_G: 2.3092708587646484\n",
            "[38/50][500/782] Loss_D: 0.7165623605251312 Loss_G: 1.9937036037445068\n",
            "[38/50][600/782] Loss_D: 0.6794530153274536 Loss_G: 2.187499523162842\n",
            "[38/50][700/782] Loss_D: 0.7102937698364258 Loss_G: 1.9158079624176025\n",
            "[39/50][0/782] Loss_D: 0.734014093875885 Loss_G: 2.301438331604004\n",
            "[39/50][100/782] Loss_D: 0.7019434571266174 Loss_G: 1.926663875579834\n",
            "[39/50][200/782] Loss_D: 0.6882370412349701 Loss_G: 2.182957410812378\n",
            "[39/50][300/782] Loss_D: 0.6909578740596771 Loss_G: 1.9232964515686035\n",
            "[39/50][400/782] Loss_D: 0.6752181053161621 Loss_G: 2.3285272121429443\n",
            "[39/50][500/782] Loss_D: 0.7215374112129211 Loss_G: 2.133471965789795\n",
            "[39/50][600/782] Loss_D: 0.6914898753166199 Loss_G: 2.035747528076172\n",
            "[39/50][700/782] Loss_D: 0.7018478810787201 Loss_G: 1.6451187133789062\n",
            "[40/50][0/782] Loss_D: 0.7331036031246185 Loss_G: 1.9830262660980225\n",
            "[40/50][100/782] Loss_D: 0.7738703191280365 Loss_G: 2.2857484817504883\n",
            "[40/50][200/782] Loss_D: 0.6982304453849792 Loss_G: 2.558858871459961\n",
            "[40/50][300/782] Loss_D: 0.7227781713008881 Loss_G: 2.550760269165039\n",
            "[40/50][400/782] Loss_D: 0.7235750257968903 Loss_G: 2.0639309883117676\n",
            "[40/50][500/782] Loss_D: 0.6746836304664612 Loss_G: 1.9334080219268799\n",
            "[40/50][600/782] Loss_D: 0.7407826483249664 Loss_G: 2.1628193855285645\n",
            "[40/50][700/782] Loss_D: 0.6996679902076721 Loss_G: 1.8299005031585693\n",
            "[41/50][0/782] Loss_D: 0.7760996222496033 Loss_G: 2.4090819358825684\n",
            "[41/50][100/782] Loss_D: 0.7542344033718109 Loss_G: 1.997554898262024\n",
            "[41/50][200/782] Loss_D: 0.7211286425590515 Loss_G: 2.378878116607666\n",
            "[41/50][300/782] Loss_D: 0.6780351102352142 Loss_G: 2.044604778289795\n",
            "[41/50][400/782] Loss_D: 0.6870488226413727 Loss_G: 2.037351131439209\n",
            "[41/50][500/782] Loss_D: 0.696892261505127 Loss_G: 1.7083213329315186\n",
            "[41/50][600/782] Loss_D: 0.681168407201767 Loss_G: 2.0333194732666016\n",
            "[41/50][700/782] Loss_D: 0.6809853315353394 Loss_G: 2.289536237716675\n",
            "[42/50][0/782] Loss_D: 0.7074521780014038 Loss_G: 1.8155007362365723\n",
            "[42/50][100/782] Loss_D: 0.6949826180934906 Loss_G: 1.843775749206543\n",
            "[42/50][200/782] Loss_D: 0.6921378672122955 Loss_G: 1.6597315073013306\n",
            "[42/50][300/782] Loss_D: 0.7388752698898315 Loss_G: 1.9953956604003906\n",
            "[42/50][400/782] Loss_D: 0.7190730571746826 Loss_G: 1.6128168106079102\n",
            "[42/50][500/782] Loss_D: 0.6780696511268616 Loss_G: 1.891562581062317\n",
            "[42/50][600/782] Loss_D: 0.6855078935623169 Loss_G: 2.346534013748169\n",
            "[42/50][700/782] Loss_D: 0.7673640251159668 Loss_G: 1.6214580535888672\n",
            "[43/50][0/782] Loss_D: 0.6847104132175446 Loss_G: 2.020961284637451\n",
            "[43/50][100/782] Loss_D: 0.6820769011974335 Loss_G: 1.924875259399414\n",
            "[43/50][200/782] Loss_D: 0.7030064463615417 Loss_G: 2.2388789653778076\n",
            "[43/50][300/782] Loss_D: 0.705219566822052 Loss_G: 1.9217634201049805\n",
            "[43/50][400/782] Loss_D: 0.6827574372291565 Loss_G: 2.089602470397949\n",
            "[43/50][500/782] Loss_D: 0.6926242709159851 Loss_G: 2.3264975547790527\n",
            "[43/50][600/782] Loss_D: 0.7071581482887268 Loss_G: 2.328953266143799\n",
            "[43/50][700/782] Loss_D: 0.7493785619735718 Loss_G: 2.209231376647949\n",
            "[44/50][0/782] Loss_D: 0.6847449839115143 Loss_G: 1.8768569231033325\n",
            "[44/50][100/782] Loss_D: 0.7023570835590363 Loss_G: 1.835320234298706\n",
            "[44/50][200/782] Loss_D: 0.6995452046394348 Loss_G: 1.8511619567871094\n",
            "[44/50][300/782] Loss_D: 0.6763713657855988 Loss_G: 2.182041645050049\n",
            "[44/50][400/782] Loss_D: 0.7056375741958618 Loss_G: 2.1605582237243652\n",
            "[44/50][500/782] Loss_D: 0.6818465888500214 Loss_G: 2.200450897216797\n",
            "[44/50][600/782] Loss_D: 0.6949217319488525 Loss_G: 1.6936008930206299\n",
            "[44/50][700/782] Loss_D: 0.6885959804058075 Loss_G: 2.2177700996398926\n",
            "[45/50][0/782] Loss_D: 0.6859516203403473 Loss_G: 1.8154438734054565\n",
            "[45/50][100/782] Loss_D: 0.6790779531002045 Loss_G: 2.309124231338501\n",
            "[45/50][200/782] Loss_D: 0.7519463896751404 Loss_G: 1.6920888423919678\n",
            "[45/50][300/782] Loss_D: 0.6942628026008606 Loss_G: 2.3302505016326904\n",
            "[45/50][400/782] Loss_D: 0.7484492361545563 Loss_G: 1.7546387910842896\n",
            "[45/50][500/782] Loss_D: 0.7133709192276001 Loss_G: 1.9477686882019043\n",
            "[45/50][600/782] Loss_D: 0.7126762568950653 Loss_G: 2.130784034729004\n",
            "[45/50][700/782] Loss_D: 0.7758270800113678 Loss_G: 1.9956724643707275\n",
            "[46/50][0/782] Loss_D: 0.6906783282756805 Loss_G: 2.1153688430786133\n",
            "[46/50][100/782] Loss_D: 0.6992962956428528 Loss_G: 1.715725064277649\n",
            "[46/50][200/782] Loss_D: 0.7296440005302429 Loss_G: 2.1876168251037598\n",
            "[46/50][300/782] Loss_D: 0.7122923731803894 Loss_G: 2.401031494140625\n",
            "[46/50][400/782] Loss_D: 0.7000440955162048 Loss_G: 2.1833713054656982\n",
            "[46/50][500/782] Loss_D: 0.7153820395469666 Loss_G: 2.3198091983795166\n",
            "[46/50][600/782] Loss_D: 0.6763832569122314 Loss_G: 2.1805038452148438\n",
            "[46/50][700/782] Loss_D: 0.7336515486240387 Loss_G: 1.6331654787063599\n",
            "[47/50][0/782] Loss_D: 0.6902465522289276 Loss_G: 2.0200488567352295\n",
            "[47/50][100/782] Loss_D: 0.6891849040985107 Loss_G: 1.888319492340088\n",
            "[47/50][200/782] Loss_D: 0.6795394122600555 Loss_G: 1.8650436401367188\n",
            "[47/50][300/782] Loss_D: 0.6987608671188354 Loss_G: 2.012430191040039\n",
            "[47/50][400/782] Loss_D: 0.7200517058372498 Loss_G: 1.7563114166259766\n",
            "[47/50][500/782] Loss_D: 0.7024298906326294 Loss_G: 1.9906201362609863\n",
            "[47/50][600/782] Loss_D: 0.7049631774425507 Loss_G: 1.8292261362075806\n",
            "[47/50][700/782] Loss_D: 0.6916645765304565 Loss_G: 2.698606252670288\n",
            "[48/50][0/782] Loss_D: 0.678604245185852 Loss_G: 2.273653268814087\n",
            "[48/50][100/782] Loss_D: 0.6900099217891693 Loss_G: 1.833808183670044\n",
            "[48/50][200/782] Loss_D: 0.7167234122753143 Loss_G: 2.4558053016662598\n",
            "[48/50][300/782] Loss_D: 0.7376048564910889 Loss_G: 1.7578706741333008\n",
            "[48/50][400/782] Loss_D: 0.6800520420074463 Loss_G: 2.1256093978881836\n",
            "[48/50][500/782] Loss_D: 0.7090074121952057 Loss_G: 1.7932631969451904\n",
            "[48/50][600/782] Loss_D: 0.6894993484020233 Loss_G: 2.0287492275238037\n",
            "[48/50][700/782] Loss_D: 0.7245182991027832 Loss_G: 2.2878828048706055\n",
            "[49/50][0/782] Loss_D: 0.6988515257835388 Loss_G: 2.5948877334594727\n",
            "[49/50][100/782] Loss_D: 0.7714918255805969 Loss_G: 2.092012405395508\n",
            "[49/50][200/782] Loss_D: 0.7076196074485779 Loss_G: 1.5598247051239014\n",
            "[49/50][300/782] Loss_D: 0.6920677125453949 Loss_G: 1.565475344657898\n",
            "[49/50][400/782] Loss_D: 0.6788435280323029 Loss_G: 2.2057275772094727\n",
            "[49/50][500/782] Loss_D: 0.7006714344024658 Loss_G: 1.9635889530181885\n",
            "[49/50][600/782] Loss_D: 0.6942412555217743 Loss_G: 2.0587737560272217\n",
            "[49/50][700/782] Loss_D: 0.6815721392631531 Loss_G: 1.3670322895050049\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPooB3uXwvXb",
        "outputId": "29412e74-1c0a-49bc-ad40-6918fa54ce20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/fake_images_epoch_7.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_33.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_29.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_47.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_38.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_24.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_39.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_32.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_42.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_5.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_26.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_6.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_40.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_35.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_30.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_11.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_28.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_17.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_19.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_46.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_25.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_34.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_37.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_36.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_27.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_23.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_31.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_22.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_15.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_41.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_16.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_8.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_1.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_2.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_3.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_45.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_14.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_9.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_49.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_4.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_12.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_18.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_43.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_20.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_0.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_44.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_10.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_13.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_48.png (deflated 0%)\n",
            "  adding: output/fake_images_epoch_21.png (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('output.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L52CPa5mAfJd",
        "outputId": "01252b3c-7ac6-4b94-c6bc-db236b840485"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_58b39a80-30dc-4e1b-a632-2c3488ec16ee\", \"output.zip\", 21570640)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming netG is your trained Generator model\n",
        "torch.save(netG.state_dict(), 'saved_generator_weights.pth')\n",
        "\n",
        "# Download the saved weights\n",
        "from google.colab import files\n",
        "files.download('saved_generator_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gz4FskrGCm_m",
        "outputId": "48837d5e-d588-4e2f-ffd7-9011cb302af1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d3e68305-3b39-44da-b87f-aa7e98a109b8\", \"saved_generator_weights.pth\", 14323291)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}